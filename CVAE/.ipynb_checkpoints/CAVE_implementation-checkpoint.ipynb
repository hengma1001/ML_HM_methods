{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "# from torchvision.utils import save_image\n",
    "\n",
    "from vae_conv_mnist import conv_variational_autoencoder \n",
    "import matplotlib.pyplot as plt \n",
    "import sys, os \n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 1\n",
    "# batch_size = cm_train.shape[0]/100\n",
    "conv_layers = 4\n",
    "feature_maps = [64,64,64,64]\n",
    "filter_shapes = [3,3,3,3]\n",
    "strides = [1,2,1,1]\n",
    "dense_layers = 2\n",
    "dense_neurons = [128, 64]\n",
    "dense_dropouts = [0.0, 0.0]\n",
    "latent_dim = 20\n",
    "\n",
    "image_size = train_loader.dataset.train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = conv_variational_autoencoder(image_size,channels,conv_layers,feature_maps,\n",
    "                                           filter_shapes,strides,dense_layers,dense_neurons,dense_dropouts,latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 469.405273\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 205.381516\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 172.821518\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 151.244354\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 133.701202\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 138.249863\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 118.703323\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 132.674347\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 118.623093\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 121.013847\n",
      "====> Epoch: 1 Average loss: 150.9879 ====> Test set loss: 119.1473\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 122.072731\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 115.345398\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 117.211868\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 108.095306\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 105.817535\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 115.263153\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 105.515259\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 104.111099\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 108.221230\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 107.279266\n",
      "====> Epoch: 2 Average loss: 110.0895 ====> Test set loss: 105.3541\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 102.375946\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 106.667389\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 107.950058\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 100.642792\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 108.552223\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 100.245712\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 100.000206\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 98.444153\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 103.538658\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 107.119865\n",
      "====> Epoch: 3 Average loss: 103.0524 ====> Test set loss: 101.1282\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 103.293991\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 95.382576\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 94.877197\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 95.845375\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 95.855255\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 104.852081\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 103.018799\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 99.699341\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 98.809074\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 98.635422\n",
      "====> Epoch: 4 Average loss: 100.3063 ====> Test set loss: 99.0949\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 99.123993\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "log_interval = 200 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "for epoch in range(1, epochs + 1): \n",
    "    autoencoder.train(train_loader, epoch) \n",
    "    autoencoder.test(test_loader, epoch) \n",
    "    \n",
    "#     with torch.no_grad(): \n",
    "#         train_all = train_loader.dataset.train_data.reshape(-1, 1, 28, 28).float()[:2000].to(device)\n",
    "# #         print(train_all.shape)\n",
    "#         decoded = autoencoder.predict(train_all) \n",
    "#         embeded = autoencoder.return_embeddings(train_all) \n",
    "#         encoded = autoencoder.encode(train_all) \n",
    "    \n",
    "#     plt.figure(figsize=(10,8))\n",
    "#     plt.scatter(embeded.cpu()[:2000,0], embeded.cpu()[:2000,1], c=train_loader.dataset.train_labels.cpu()[:2000], cmap='tab10') \n",
    "#     plt.title('Epoch: %d' % epoch)\n",
    "#     plt.colorbar() \n",
    "#     plt.savefig('./results/3_result_epoch%d.pdf' % epoch) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print autoencoder.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# linearly spaced coordinates corresponding to the 2D plot\n",
    "# of digit classes in the latent space\n",
    "grid_x = np.linspace(-200, 200, n)\n",
    "grid_y = np.linspace(-200, 200, n)[::-1]\n",
    "\n",
    "for i, yi in enumerate(grid_y):\n",
    "    for j, xi in enumerate(grid_x):\n",
    "        z_sample = torch.tensor([[xi, yi]]).to(device) \n",
    "        with torch.no_grad(): \n",
    "            x_decoded = autoencoder.decode(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit.cpu()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "start_range = digit_size // 2\n",
    "end_range = n * digit_size + start_range + 1\n",
    "pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "sample_range_x = np.round(grid_x, 1)\n",
    "sample_range_y = np.round(grid_y, 1)\n",
    "plt.xticks(pixel_range, sample_range_x)\n",
    "plt.yticks(pixel_range, sample_range_y)\n",
    "plt.xlabel(\"z[0]\")\n",
    "plt.ylabel(\"z[1]\")\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epochs = 1\n",
    "log_interval = 100\n",
    "for epoch in range(1, epochs + 1): \n",
    "    autoencoder.train(train_loader, epoch) \n",
    "    autoencoder.test(test_loader, epoch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "with torch.no_grad(): \n",
    "    train_all = train_loader.dataset.train_data.reshape(-1, 1, 28, 28).float()[:2000].to(device)\n",
    "    print(train_all.shape)\n",
    "    decoded = autoencoder.predict(train_all) \n",
    "    embeded = autoencoder.return_embeddings(train_all) \n",
    "    encoded = autoencoder.encode(train_all) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fig, ax = plt.subplots(nrows=2, ncols=4) \n",
    "\n",
    "for i in range(4): \n",
    "    ax[0,i].imshow(np.squeeze(train_all.cpu())[i]) \n",
    "    ax[0,i].set_title('original')\n",
    "    ax[1,i].imshow(np.squeeze(decoded.cpu())[i]) \n",
    "    ax[1,i].set_title('generated')\n",
    "    ax[0,i].axis('off') \n",
    "    ax[1,i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(embeded.cpu()[:2000,0], embeded.cpu()[:2000,1], c=train_loader.dataset.train_labels.cpu()[:2000], cmap='tab10')\n",
    "plt.colorbar() \n",
    "plt.xlim((-500, 500))\n",
    "plt.ylim((-500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
